{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Autoencoder\n",
    "_(Requires Python 3, PyTorch 1.0.1, TorchVision 0.2.2)_\n",
    "\n",
    "**Reference**: _A.Makhzani et al.,_ [Adversarial Autoencoders](https://arxiv.org/abs/1511.05644)\n",
    "\n",
    "### Libraries\n",
    "Import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll also need numpy and matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "The Adversarial Autoencoder exploits the same trick of the Variational AutoEncoder: enforcing a prior distribution on the latent space. In this case, however, the distribution is enforced using an adversarial network named _discriminator_. The role of the discriminator is to distringuish the samples generated by the encoder (_fake_ samples) from actual samples of the imposed distribution (_true_ samples).\n",
    "\n",
    "The learning proceeds in a two-player-game fashion:\n",
    "- **Discriminator**: Aims to distinguish the samples generated by the encoder from samples taken from the objective distribution.\n",
    "- **Autoencoder**: Maximizes the similarity between the input and the output samples. At the same time, tries to fool the discriminator by mimicking the objective distribution in the latent space.\n",
    "\n",
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dims, lat_dim, activations=func.relu):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # Parse input arguments\n",
    "        if type(hidden_dims) == int:\n",
    "            hidden_dims = [hidden_dims,]\n",
    "\n",
    "        if type(activations) == list:\n",
    "            if len(activations) != len(hidden_dims):\n",
    "                raise ValueError('activations and hidden_dims must have the same dimensions')\n",
    "        else:\n",
    "            activations = [activations]*len(hidden_dims)\n",
    "\n",
    "        # Store arguments\n",
    "        self.hidden_dims = np.array(hidden_dims)\n",
    "        self.activations = activations\n",
    "        \n",
    "        # Create layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        prev_d = input_dim\n",
    "        for d in hidden_dims:\n",
    "            self.layers.append(nn.Linear(prev_d, d))\n",
    "            prev_d = d\n",
    "            \n",
    "        # Latent layer\n",
    "        self.layers.append(nn.Linear(prev_d, lat_dim))\n",
    "        self.activations.append(lambda x: x)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer, activation in zip(self.layers, self.activations):\n",
    "            x = activation(layer(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, lat_dim, hidden_dims, output_dim, activations=func.relu):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # Parse input arguments\n",
    "        if type(hidden_dims) == int:\n",
    "            hidden_dims = [hidden_dims,]\n",
    "        \n",
    "        if type(activations) == list:\n",
    "            if len(activations) != len(hidden_dims):\n",
    "                raise ValueError('activations and hidden_dims must have the same dimensions')\n",
    "        else:\n",
    "            activations = [activations]*len(hidden_dims)\n",
    "            \n",
    "        # Store arguments\n",
    "        self.hidden_dims = np.array(hidden_dims)\n",
    "        self.activations = activations\n",
    "        activations.append(torch.sigmoid)\n",
    "        \n",
    "        # Create layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        prev_d = lat_dim\n",
    "        for d in self.hidden_dims:\n",
    "            self.layers.append(nn.Linear(prev_d, d))\n",
    "            prev_d = d\n",
    "            \n",
    "        # Output layer\n",
    "        self.layers.append(nn.Linear(prev_d, output_dim))\n",
    "\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for layer, activation in zip(self.layers, self.activations):\n",
    "            x = activation(layer(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, lat_dim, hidden_dims, activations=func.relu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Parse input arguments\n",
    "        if type(hidden_dims) == int:\n",
    "            hidden_dims = [hidden_dims,]\n",
    "        \n",
    "        if type(activations) == list:\n",
    "            if len(activations) != len(hidden_dims):\n",
    "                raise ValueError('activations and hidden_dims must have the same dimensions')\n",
    "        else:\n",
    "            activations = [activations]*len(hidden_dims)\n",
    "            \n",
    "        # Store arguments\n",
    "        self.hidden_dims = np.array(hidden_dims)\n",
    "        self.activations = activations\n",
    "        activations.append(torch.sigmoid)\n",
    "        \n",
    "        # Create layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        prev_d = lat_dim\n",
    "        for d in self.hidden_dims:\n",
    "            self.layers.append(nn.Linear(prev_d, d))\n",
    "            prev_d = d\n",
    "            \n",
    "        # Output layer\n",
    "        self.layers.append(nn.Linear(prev_d, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer, activation in zip(self.layers, self.activations):\n",
    "            x = activation(layer(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adversarial Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialAutoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dims, lat_dim, activation=func.relu):\n",
    "        super(AdversarialAutoencoder, self).__init__()\n",
    "        \n",
    "        # Create encoder\n",
    "        self.encoder = Encoder(input_dim, hidden_dims, lat_dim, activation)\n",
    "        \n",
    "        # Create decoder\n",
    "        self.decoder = Decoder(lat_dim, np.flip(np.array(hidden_dims)), input_dim, activation)\n",
    "        \n",
    "        # Create discriminator\n",
    "        self.discrim = Discriminator(lat_dim, np.flip(np.array(hidden_dims)), activation)\n",
    "        \n",
    "        # Set status\n",
    "        self.status = 'train'\n",
    "        \n",
    "    def set_status(self, s):\n",
    "        self.status = s\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        if self.status == 'train':\n",
    "            y = self.decoder(x)\n",
    "            d = self.discrim(x)\n",
    "            return y, d\n",
    "        \n",
    "        elif self.status == 'discriminate':\n",
    "            d = self.discrim(x)\n",
    "            return d\n",
    "        \n",
    "        else:\n",
    "            y = self.decoder(x)\n",
    "            return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training example\n",
    "\n",
    "### Training Data\n",
    "Let's train the denoising autoencoder on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "train = torchvision.datasets.MNIST('./', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "test = torchvision.datasets.MNIST('./', train=False, download=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim  = 28*28\n",
    "layers     = [200,100,30]\n",
    "latent_dim = 2\n",
    "\n",
    "aae = AdversarialAutoencoder(input_dim, layers, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aae_optimizer = torch.optim.Adam(aae.parameters(), lr=0.001)\n",
    "fool_optimizer = torch.optim.Adam(aae.encoder.parameters(), lr=0.001)\n",
    "discrim_optimizer = torch.optim.Adam(aae.discrim.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "n_test_img = 6\n",
    "epochs     = 15\n",
    "batch_size = 100\n",
    "\n",
    "# Reshape data\n",
    "train_samples = train.data.view(-1, 28*28).type(torch.float32)/255.0\n",
    "test_samples  = test.data.view(-1,28*28).type(torch.float32)/255.0\n",
    "\n",
    "# Lists to store training losses\n",
    "train_loss = []\n",
    "test_loss  = []\n",
    "\n",
    "# Set model to training mode\n",
    "aae.train()\n",
    "\n",
    "# Plot test input images\n",
    "test_imgs = test.data[0:n_test_img,:].type(torch.float32).view(-1,28*28)/255.0\n",
    "f, a = plt.subplots(2, n_test_img, figsize=(8, 3))\n",
    "for i in range(n_test_img):\n",
    "    a[0][i].imshow(255-np.reshape(test_imgs.data.numpy()[i], (28,28)), cmap='gray')\n",
    "    a[0][i].set_xticks(())\n",
    "    a[0][i].set_yticks(())\n",
    "    \n",
    "loss_text = f.text(0, 0, \"epoch: 0, loss: 0\")\n",
    "\n",
    "# Discriminator targets\n",
    "target_true = torch.ones(batch_size,1)\n",
    "target_fake = torch.ones(batch_size,1)\n",
    "\n",
    "# Data iterator\n",
    "train_batches = Data.DataLoader(dataset=train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "for e in np.arange(epochs):\n",
    "    batch_loss = [0, 0, 0]\n",
    "    for batch_no, (batch, batch_labels) in enumerate(train_batches):\n",
    "        # Input and target data (flatten)\n",
    "        b_in = batch.view(-1, 28*28)\n",
    "        target_autoenc = batch.view(-1, 28*28)\n",
    "        \n",
    "        ## Train AAE\n",
    "        aae.set_status('train')\n",
    "        # Forward pass of the data through the network\n",
    "        y, d = aae(b_in)\n",
    "        # Compute the AAE Losses\n",
    "        autoenc_loss = func.binary_cross_entropy(y, target_autoenc)\n",
    "        discrim_loss = func.binary_cross_entropy(d, target_fake)\n",
    "        # Total loss \n",
    "        aae_loss = autoenc_loss + discrim_loss\n",
    "        batch_loss[0] += aae_loss\n",
    "        # Reset the gradients\n",
    "        aae_optimizer.zero_grad()\n",
    "        # Compute gradients\n",
    "        aae_loss.backward()\n",
    "        # Update AAE parameters\n",
    "        aae_optimizer.step()\n",
    "        \n",
    "        ## Train Discriminator\n",
    "        # Forward samples from prior distribution\n",
    "        d = aae.discrim(torch.randn(batch_size, latent_dim))\n",
    "        # Compute loss\n",
    "        discrim_loss = func.binary_cross_entropy(d, target_true)\n",
    "        batch_loss[1] += discrim_loss\n",
    "        # Reset gradients\n",
    "        aae_optimizer.zero_grad()\n",
    "        # Compute gradients\n",
    "        discrim_loss.backward()\n",
    "        # Update Discriminator parameters\n",
    "        discrim_optimizer.step()\n",
    "        \n",
    "        ## Train Encoder to fool\n",
    "        aae.set_status('discriminate')\n",
    "        # Forward samples from encoder to discriminator\n",
    "        d = aae(b_in)\n",
    "        # Compute loss\n",
    "        fool_loss = func.binary_cross_entropy(d, target_true)\n",
    "        batch_loss[2] += fool_loss\n",
    "        # Reset gradients\n",
    "        aae_optimizer.zero_grad()\n",
    "        # Compute gradients\n",
    "        fool_loss.backward()\n",
    "        # Update Encoder parameters\n",
    "        fool_optimizer.step()\n",
    "\n",
    "        # Test images\n",
    "        if batch_no % 50 == 0:\n",
    "            aae.set_status('test')\n",
    "            test_out = aae(test_imgs)\n",
    "            for i in range(n_test_img):\n",
    "                a[1][i].imshow(1.0-np.reshape(test_out.data.numpy()[i], (28,28)), cmap='gray')\n",
    "                a[1][i].set_xticks(())\n",
    "                a[1][i].set_yticks(())\n",
    "            loss_text.set_text(\"epoch: {}, aae loss: {:.3f}, discim loss: {:.3f}, fool loss: {:.3f}\".format(e+1, aae_loss, discrim_loss, fool_loss))\n",
    "            f.canvas.draw()\n",
    "\n",
    "    # End of epoch, compute train & test loss\n",
    "    aae.set_status('test')\n",
    "    train_loss.append(batch_loss[0]/batch_no)\n",
    "    test_loss.append(func.binary_cross_entropy(aae(test_samples), test_samples))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss)\n",
    "plt.plot(test_loss)\n",
    "plt.legend(['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "### Loss on test dataset\n",
    "We can easily compute the Loss by evaluating the loss function on the output data:\n",
    "\n",
    "#### Train Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train loss: {}\".format(train_loss[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test loss: {}\".format(test_loss[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent space\n",
    "The projections of the test images in the latent space after training look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d = aae.encoder(test_samples)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(test_d.data.numpy()[:,0], test_d.data.numpy()[:,1], c=test.targets.numpy(), s=1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d = aae.encoder(train_samples)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(test_d.data.numpy()[:,0], test_d.data.numpy()[:,1], c=train.targets.numpy(), s=1.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
