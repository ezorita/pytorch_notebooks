{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Autoencoder\n",
    "_(Requires Python 3, PyTorch 1.0.1, TorchVision 0.2.2)_\n",
    "\n",
    "### Libraries\n",
    "Import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll also need numpy and matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "This consists in the encoder and decoder block. The main difference with an autoencoder is that we add noise to the input data. The cost function is the binary crossentropy between the noise-free input and the reconstructed output.\n",
    "\n",
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dims, lat_dim, activations=func.relu):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # Parse input arguments\n",
    "        if type(hidden_dims) == int:\n",
    "            hidden_dims = [hidden_dims,]\n",
    "\n",
    "        if type(activations) == list:\n",
    "            if len(activations) != len(hidden_dims):\n",
    "                raise ValueError('activations and hidden_dims must have the same dimensions')\n",
    "        else:\n",
    "            activations = [activations]*len(hidden_dims)\n",
    "\n",
    "        # Store arguments\n",
    "        self.hidden_dims = np.array(hidden_dims)\n",
    "        self.activations = activations\n",
    "        \n",
    "        # Create layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        prev_d = input_dim\n",
    "        for d in hidden_dims:\n",
    "            self.layers.append(nn.Linear(prev_d, d))\n",
    "            prev_d = d\n",
    "            \n",
    "        # Latent layer\n",
    "        self.layers.append(nn.Linear(prev_d, lat_dim))\n",
    "        self.activations.append(lambda x: x)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer, activation in zip(self.layers, self.activations):\n",
    "            x = activation(layer(x))\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, lat_dim, hidden_dims, output_dim, activations=func.relu):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # Parse input arguments\n",
    "        if type(hidden_dims) == int:\n",
    "            hidden_dims = [hidden_dims,]\n",
    "        \n",
    "        if type(activations) == list:\n",
    "            if len(activations) != len(hidden_dims):\n",
    "                raise ValueError('activations and hidden_dims must have the same dimensions')\n",
    "        else:\n",
    "            activations = [activations]*len(hidden_dims)\n",
    "            \n",
    "        # Store arguments\n",
    "        self.hidden_dims = np.array(hidden_dims)\n",
    "        self.activations = activations\n",
    "        activations.append(torch.sigmoid)\n",
    "        \n",
    "        # Create layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        prev_d = lat_dim\n",
    "        for d in self.hidden_dims:\n",
    "            self.layers.append(nn.Linear(prev_d, d))\n",
    "            prev_d = d\n",
    "            \n",
    "        # Output layer\n",
    "        self.layers.append(nn.Linear(prev_d, output_dim))\n",
    "\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for layer, activation in zip(self.layers, self.activations):\n",
    "            x = activation(layer(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingAutoencoder(nn.Module):\n",
    "    # Mou el tema del noise aqui i treu-lo del encoder!!\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dims, lat_dim, activations=func.relu, noise='salt-pepper', noise_p=0.3):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        \n",
    "        # Parse arguments\n",
    "        if type(hidden_dims) == int:\n",
    "            hidden_dims = [hidden_dims,]\n",
    "            \n",
    "        if noise not in ['salt-pepper',]:\n",
    "            raise ValueError('noise options: salt-pepper')\n",
    "        \n",
    "        # Store arguments\n",
    "        self.noise = noise\n",
    "        self.noise_p = noise_p\n",
    "        \n",
    "        # Build encoder and decoder\n",
    "        h_dim = np.array(hidden_dims)\n",
    "        self.encoder = Encoder(input_dim, h_dim, lat_dim, activations)\n",
    "        self.decoder = Decoder(lat_dim, np.flip(h_dim), input_dim, activations)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_n = self.apply_noise(x)\n",
    "        lat = self.encoder(x_n)\n",
    "        out = self.decoder(lat)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def apply_noise(self, x):\n",
    "        x_n = x.clone()\n",
    "        if self.noise == 'salt-pepper':\n",
    "            idx = np.where(np.random.random(x.shape) < self.noise_p)\n",
    "            val = torch.Tensor(np.array(np.random.random(len(idx[0])) < 0.5, dtype=int))\n",
    "            x_n[idx] = val\n",
    "\n",
    "        return x_n\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training example\n",
    "\n",
    "### Training Data\n",
    "Let's train the denoising autoencoder on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "train = torchvision.datasets.MNIST('./', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "test = torchvision.datasets.MNIST('./', train=False, download=True, transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim  = 28*28\n",
    "layers     = [200,100,30]\n",
    "latent_dim = 2\n",
    "\n",
    "noise_p = 0.3\n",
    "\n",
    "autoencoder = DenoisingAutoencoder(input_dim, layers, latent_dim, noise_p = noise_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = func.binary_cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "n_test_img = 4\n",
    "epochs     = 10\n",
    "batch_size = 100\n",
    "\n",
    "# Reshape data\n",
    "train_samples = train.data.view(-1, 28*28).type(torch.float32)/255.0\n",
    "test_samples  = test.data.view(-1,28*28).type(torch.float32)/255.0\n",
    "\n",
    "# Lists to store training losses\n",
    "train_loss = []\n",
    "test_loss  = []\n",
    "\n",
    "# Plot test input images\n",
    "test_imgs = test.data[0:n_test_img,:].type(torch.float32).view(-1,28*28)/255.0\n",
    "f, a = plt.subplots(2, n_test_img, figsize=(8, 3))\n",
    "for i in range(n_test_img):\n",
    "    a[0][i].imshow(255-np.reshape(test_imgs.data.numpy()[i], (28,28)), cmap='gray')\n",
    "    a[0][i].set_xticks(())\n",
    "    a[0][i].set_yticks(())\n",
    "    \n",
    "loss_text = f.text(0, 0, \"epoch: 0, loss: 0\")\n",
    "\n",
    "# Data iterator\n",
    "train_batches = Data.DataLoader(dataset=train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for e in np.arange(epochs):\n",
    "    batch_loss = 0\n",
    "    for batch_no, (batch, batch_labels) in enumerate(train_batches):\n",
    "        # Input and target data (flatten)\n",
    "        b_in = batch.view(-1, 28*28)\n",
    "        target = batch.view(-1, 28*28)\n",
    "        # Forward pass of the data through the network\n",
    "        out  = autoencoder(b_in)\n",
    "        # Compute the Loss\n",
    "        loss = loss_func(out, target)\n",
    "        batch_loss += loss\n",
    "        # Reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Update the gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Test images\n",
    "        if batch_no % 50 == 0:\n",
    "            test_out = autoencoder(test_imgs)\n",
    "            for i in range(n_test_img):\n",
    "                a[1][i].imshow(1.0-np.reshape(test_out.data.numpy()[i], (28,28)), cmap='gray')\n",
    "                a[1][i].set_xticks(())\n",
    "                a[1][i].set_yticks(())\n",
    "            loss_text.set_text(\"epoch: {}, loss: {:.3f}\".format(e+1, loss))\n",
    "            f.canvas.draw()\n",
    "            \n",
    "    # Compute batch loss\n",
    "    train_loss.append(batch_loss/batch_no)\n",
    "    test_loss.append(func.binary_cross_entropy(autoencoder(test_samples), test_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss)\n",
    "plt.plot(test_loss)\n",
    "plt.legend([\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "### Loss on test dataset\n",
    "We can easily compute the Loss by evaluating the loss function on the output data:\n",
    "\n",
    "#### Train Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train loss: {}\".format(train_loss[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test loss: {}\".format(test_loss[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent space\n",
    "The projections of the test images in the latent space after training look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lat = autoencoder.encoder(test_samples).data.numpy()\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(test_lat[:,0], test_lat[:,1], c=test.targets.numpy(), s=1.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
